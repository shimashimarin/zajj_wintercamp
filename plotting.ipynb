{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第三章 `Data`和`Prediction`的对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema, BaseSchema\n",
    "from coffea import util\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import uproot as up\n",
    "from coffea import hist as coffea_hist\n",
    " \n",
    "# from coffea import hist,processor\n",
    "from coffea import processor\n",
    "from coffea.nanoevents.methods import candidate\n",
    "ak.behavior.update(candidate.behavior)\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import time\n",
    "\n",
    "from hist import Hist, axis\n",
    "import hist\n",
    "\n",
    "import pickle\n",
    "\n",
    "hep.cms.style.CMS[\"xtick.major.width\"]=2\n",
    "hep.cms.style.CMS[\"ytick.major.width\"]=2\n",
    "hep.cms.style.CMS[\"xtick.minor.width\"]=2\n",
    "# hep.cms.style.CMS[\"xtick.minor.visible\"]=False\n",
    "hep.cms.style.CMS[\"ytick.minor.width\"]=2\n",
    "hep.cms.style.CMS[\"xtick.major.size\"]=14\n",
    "hep.cms.style.CMS[\"xtick.minor.size\"]=7\n",
    "hep.cms.style.CMS[\"ytick.major.size\"]=14\n",
    "hep.cms.style.CMS[\"ytick.minor.size\"]=7\n",
    "hep.cms.style.CMS[\"legend.handlelength\"]=1\n",
    "hep.cms.style.CMS[\"legend.handleheight\"]=1\n",
    "hep.cms.style.CMS[\"axes.linewidth\"]=3\n",
    "plt.style.use(hep.style.CMS)\n",
    "# plt.style.use(hep.style.ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_bands, ratio_hist, get_true_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bands(_up,_down,_edges):\n",
    "    xaxis,up,down=[],[],[]\n",
    "    for i,j in zip(_up,_down): \n",
    "        up.append(i)\n",
    "        down.append(j)\n",
    "        up.append(i)\n",
    "        down.append(j)\n",
    "    for i in _edges: \n",
    "        xaxis.append(i)\n",
    "        xaxis.append(i)\n",
    "    xaxis=xaxis[1:-1]\n",
    "    return xaxis,up,down\n",
    "\n",
    "def ratio_hist(content1, yerr1, content2, yerr2, _edges):\n",
    "    # content1, yerr1 = hist1.values(), np.sqrt(hist1.variances())\n",
    "    # content2, yerr2 = hist2.values(), np.sqrt(hist2.variances())\n",
    "    # _edges=hist1.axes[0].edges\n",
    "    content=[]\n",
    "    yerr=[]\n",
    "    # if you only show one error, then you may want to use the error propagation\n",
    "    #for i,ibin in enumerate(content1):\n",
    "    #    try:\n",
    "    #        tmp_con=(content2[i]/content1[i])\n",
    "    #        tmp_err=np.sqrt(tmp_con*tmp_con*(pow(yerr1[i]/content1[i],2)+pow(yerr2[i]/content2[i],2)))\n",
    "    #        content.append(tmp_con)\n",
    "    #        yerr.append(tmp_err)\n",
    "    #    except:\n",
    "    #        content.append(0)\n",
    "    #        yerr.append(0)        \n",
    "\n",
    "    # for the ratio plot, you show both the error of the numerator and the error of the denominator\n",
    "    for i,ibin in enumerate(content1):\n",
    "        try:\n",
    "            if content1[i]>0:\n",
    "                tmp_con = (content2[i]/content1[i])\n",
    "                # tmp_err = (yerr2[i]/content2[i])*(content2[i]/content1[i])\n",
    "                tmp_err = (yerr2[i]/content1[i])\n",
    "                content.append(tmp_con)\n",
    "                yerr.append(tmp_err)\n",
    "            else:\n",
    "                content.append(0)\n",
    "                yerr.append(0)        \n",
    "        except:\n",
    "            content.append(0)\n",
    "            yerr.append(0)        \n",
    "\n",
    "    return np.array(content),np.array(yerr),np.array(_edges)\n",
    "\n",
    "def get_true_err(central_val, stat_err, sys_up, sys_down):\n",
    "    _up = central_val + np.sqrt(stat_err*stat_err+sys_up*sys_up)\n",
    "    _down = central_val - np.sqrt(stat_err*stat_err+sys_down*sys_down)\n",
    "    return _up,_down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot(region,channel,varibale,hists,year=\"2016\",hist_scale=1.4,blind=False):\n",
    "    lumi = {\n",
    "        \"2016\": 36.33,\n",
    "        \"2017\": 41.53,\n",
    "        \"ALL\": 77.86,\n",
    "    } \n",
    "    which_year = {\n",
    "        \"2016\": \"2016\",\n",
    "        \"2017\": \"2017\",\n",
    "        \"ALL\": \"2016+2017\",\n",
    "    } \n",
    "    hstyle = {\n",
    "        'others':{'name':'Others','color':'#7fc97f'},\n",
    "        'za_ewk':{'name':'EW Z$\\gamma$jj','color':'#beaed4'},\n",
    "        'za_qcd':{'name':'Z$\\gamma$ QCD','color':'#fdc086'},\n",
    "        'fake':{'name':'Fake $\\gamma$','color':'cyan'},\n",
    "        'data':{'name':'Data','color':'black'},\n",
    "    }\n",
    "\n",
    "    hdata_val = hists['data'].values()\n",
    "    hdata_err = np.sqrt(hists['data'].variances())\n",
    "    hpred_val = hists['total_pred'].values()\n",
    "    hpred_err = np.sqrt(hists['total_pred'].variances())\n",
    "    hpred_up_val = hists['total_pred'].values()\n",
    "    hpred_down_val = hists['total_pred'].values()\n",
    "\n",
    "    _up,_down = get_true_err(hpred_val, hpred_err, np.abs(hpred_up_val-hpred_val), np.abs(hpred_val-hpred_down_val))\n",
    "\n",
    "    _edges = hists['data'].axes.edges[0]\n",
    "    \n",
    "    f, ax = plt.subplots(2,1,figsize=(8,8),gridspec_kw={'height_ratios': [3.1, 0.9]},sharex=True)\n",
    "    \n",
    "    sample_names = ['others','fake','za_qcd','za_ewk']\n",
    "    # ax[0]\n",
    "    xaxis,up,down = get_bands(_up,_down,_edges)\n",
    "    ax[0].fill_between(xaxis,up,down,color='gray', alpha=0.25, zorder=2.5,edgecolor=\"black\",linewidth=0, label='Pred. unc.', hatch=\"\\\\\")\n",
    "    hep.histplot([hists[i].values() for i in sample_names], bins=_edges, edges=False,histtype=\"fill\", stack=True, color=[hstyle[i]['color'] for i in sample_names],label=[hstyle[i]['name'] for i in sample_names],linewidth=0,ax=ax[0])\n",
    "    if not blind:\n",
    "        hep.histplot(hdata_val, bins=_edges, yerr=hdata_err, edges=False,histtype=\"errorbar\", stack=False, color='black',label=hstyle['data']['name'],marker='o',ax=ax[0], markersize=6, elinewidth=2) #\n",
    "    ax[0].set_ylabel('Events/bin', ha='right', y=1.0)\n",
    "    _ymax0 = max(hdata_val)\n",
    "    _ymax0 = max(hpred_val) if _ymax0<max(hpred_val) else _ymax0\n",
    "    ax[0].set_xlabel('', ha='right', x=1.0)\n",
    "    ax[0].set_ylim(0,hist_scale*_ymax0)\n",
    "\n",
    "    # set the legend\n",
    "    leg_handles,leg_labels = ax[0].get_legend_handles_labels()\n",
    "    # print(leg_handles,leg_labels)\n",
    "    # the last two are uncertainty, data\n",
    "    leg_handles_new = [leg_handles[-1]]\n",
    "    leg_labels_new  = [leg_labels[-1]]\n",
    "    for i in range(1,len(leg_handles)):\n",
    "        leg_handles_new.append(leg_handles[i-1])\n",
    "        leg_labels_new.append(leg_labels[i-1])\n",
    "    ax[0].legend(leg_handles_new,leg_labels_new,loc='upper left', ncol=3, fontsize=17)\n",
    "    \n",
    "           \n",
    "    # ax[0].tick_params(axis='x',which='both',length=0)\n",
    "    # ax[1] ratio\n",
    "    content,yerr,_edges=ratio_hist(hpred_val,hpred_err,hpred_val,hpred_err,_edges)\n",
    "    xaxis1,up1,down1=get_bands(_up/hpred_val,_down/hpred_val,_edges)\n",
    "    _ymax1 = max(yerr)\n",
    "    _ymin1 = -_ymax1\n",
    "    ax[1].fill_between(xaxis1,up1,down1,color='gray', alpha=0.25, zorder=1,edgecolor=\"black\",linewidth=0, hatch=\"\\\\\")\n",
    "    ax[1].axhline(y=1,linestyle='--',linewidth=2,alpha=0.7,color='gray')\n",
    "    content,yerr,_edges=ratio_hist(hpred_val,_up/hpred_val-1,hdata_val,hdata_err,_edges)\n",
    "    _ymax1 = _ymax1 if _ymax1>max(content+yerr) else max(content+yerr)\n",
    "    _ymin1 = _ymin1 if _ymin1<min(content-yerr) else min(content-yerr)\n",
    "    # ax[1].set_ylim(max(0,1.33*(_ymin1-1)+1),1.33*(_ymax1-1)+1)\n",
    "    if not blind:\n",
    "        hep.histplot(content, bins=_edges, yerr=yerr,histtype=\"errorbar\",ax=ax[1],marker='o',color=\"black\", markersize=6,elinewidth=2) #,label=\"GE./Roc.-1\"\n",
    "    ax[1].set_ylabel(r'$\\frac{Data}{Prediction}$', ha='center',fontsize=30)#va='baseline')\n",
    "    ax[1].set_xlabel(hists['data'].axes.label[0], ha='right', x=1.0)\n",
    "    ax[1].set_xlim(_edges[0],_edges[-1])\n",
    "    # ax[1].set_ylim(0.48,1.52)\n",
    "    plt.subplots_adjust(hspace=0.06)\n",
    "    hep.cms.label(label=f\"Preliminary: {region}, {channel}\",loc=0,data=True,year=which_year[year],lumi=lumi[year],ax=ax[0],fontsize=15)\n",
    "    # if not os.path.exists(save_path):\n",
    "    #     os.makedirs(save_path)\n",
    "    \n",
    "    # if postfit:\n",
    "    #     plt.savefig(f'{save_path}/postfit.png',bbox_inches='tight')\n",
    "    #     plt.savefig(f'{save_path}/postfit.pdf',bbox_inches='tight')\n",
    "    # else:\n",
    "    #     plt.savefig(f'{save_path}/prefit.png',bbox_inches='tight')\n",
    "    #     plt.savefig(f'{save_path}/prefit.pdf',bbox_inches='tight')\n",
    "    # # hep.cms.lumitext(cate,ax[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 载入之前存储的图片\n",
    "\n",
    "with open(\"plots/plot_2016.pkl\", \"rb\") as f:\n",
    "    hists = pickle.load(f)\n",
    "\n",
    "for iregion in hists:\n",
    "    for ichannel in hists[iregion]:\n",
    "        for ivar in hists[iregion][ichannel]:\n",
    "            if ivar == \"mll\":\n",
    "            # if True:\n",
    "                print(\"============> 2016:\",iregion,ichannel,ivar)\n",
    "                if iregion==\"SR\":\n",
    "                    get_plot(iregion,ichannel,ivar,hists[iregion][ichannel][ivar],year=\"2016\",blind=True)\n",
    "                else:\n",
    "                    get_plot(iregion,ichannel,ivar,hists[iregion][ichannel][ivar],year=\"2016\",blind=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"plots/plot_2017.pkl\", \"rb\") as f:\n",
    "    hists = pickle.load(f)\n",
    "\n",
    "for iregion in hists:\n",
    "    for ichannel in hists[iregion]:\n",
    "        for ivar in hists[iregion][ichannel]:\n",
    "            if ivar == \"mll\":\n",
    "            # if True:\n",
    "                print(\"============> 2017:\",iregion,ichannel,ivar)\n",
    "                if iregion==\"SR\":\n",
    "                    get_plot(iregion,ichannel,ivar,hists[iregion][ichannel][ivar],year=\"2017\",blind=True)\n",
    "                else:\n",
    "                    get_plot(iregion,ichannel,ivar,hists[iregion][ichannel][ivar],year=\"2017\",blind=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(\"plots/plot_combine.pkl\", \"rb\") as f:\n",
    "    hists = pickle.load(f)\n",
    "\n",
    "for iregion in hists:\n",
    "    for ichannel in hists[iregion]:\n",
    "        for ivar in hists[iregion][ichannel]:\n",
    "            if ivar == \"mll\":\n",
    "            # if True:\n",
    "                print(\"============> 2016+2017:\",iregion,ichannel,ivar)\n",
    "                if iregion==\"SR\":\n",
    "                    get_plot(iregion,ichannel,ivar,hists[iregion][ichannel][ivar],year=\"ALL\",blind=True)\n",
    "                else:\n",
    "                    get_plot(iregion,ichannel,ivar,hists[iregion][ichannel][ivar],year=\"ALL\",blind=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 练习\n",
    "\n",
    "1. 画出其他变量（\"mjj\",\"mjj_detajj\"）\n",
    "2. 画出SR中的Data\n",
    "\n",
    "# 问题\n",
    "\n",
    "1. 考虑光子出现的位置，信号在探测器桶部（Barrel）区域的事例数多，还是端盖（Endcap）？"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5cb26a57e8c3bacca127120453f50d259d8e56da38e094311726df11d012d06d"
  },
  "kernelspec": {
   "display_name": "Python [conda env:wintercamp]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
