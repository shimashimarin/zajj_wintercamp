{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema, BaseSchema\n",
    "from coffea import util\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import uproot as up\n",
    "from coffea import hist as coffea_hist\n",
    " \n",
    "# from coffea import hist,processor\n",
    "from coffea import processor\n",
    "from coffea.nanoevents.methods import candidate\n",
    "ak.behavior.update(candidate.behavior)\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import time\n",
    "\n",
    "from hist import Hist, axis\n",
    "import hist\n",
    "\n",
    "import pickle\n",
    "\n",
    "import boost_histogram as bh\n",
    "import os\n",
    "\n",
    "plt.style.use(hep.style.CMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57817eae-3300-42ae-b6c2-6823414ccf7b",
   "metadata": {},
   "source": [
    "## file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7495ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/data/pubfs/xiaoj/zajj/nb/ntuples/\"\n",
    "files = {\n",
    "    2016:{\n",
    "        \"mc\":{\n",
    "            'za_qcd':[f\"{base_dir}/2016_mc_za_qcd.root\"],\n",
    "            'za_ewk':[f\"{base_dir}/2016_mc_za_ewk.root\"],\n",
    "            'others':[\n",
    "                f\"{base_dir}/2016_mc_others.root\",\n",
    "            ]\n",
    "        },\n",
    "        \"data\":{\n",
    "            'data': [\n",
    "                f\"{base_dir}/2016_data_data.root\",\n",
    "            ]\n",
    "        },\n",
    "        \"fake\":{\n",
    "            'fake': [\n",
    "                f\"{base_dir}/2016_fake_fake.root\",\n",
    "            ]\n",
    "        },\n",
    "        \"fake_up\":{\n",
    "            'fake_up': [\n",
    "                f\"{base_dir}/2016_fake_up_fake.root\",\n",
    "            ]\n",
    "        },\n",
    "        \"fake_down\":{\n",
    "            'fake_down': [\n",
    "                f\"{base_dir}/2016_fake_down_fake.root\",\n",
    "            ],\n",
    "        },\n",
    "        \"JEC_up\":{\n",
    "            'za_qcd_JEC_up':[f\"{base_dir}/2016_jesr_za_qcd.root\"],\n",
    "            'za_ewk_JEC_up':[f\"{base_dir}/2016_jesr_za_ewk.root\"],\n",
    "            'others_JEC_up':[\n",
    "                f\"{base_dir}/2016_jesr_others2.root\",\n",
    "            ]\n",
    "         },     \n",
    "        \"JEC_down\":{\n",
    "            'za_qcd_JEC_down':[f\"{base_dir}/2016_jesr_za_qcd.root\"],\n",
    "            'za_ewk_JEC_down':[f\"{base_dir}/2016_jesr_za_ewk.root\"],\n",
    "            'others_JEC_down':[\n",
    "                f\"{base_dir}/2016_jesr_others2.root\",\n",
    "            ]\n",
    "         },     \n",
    "        \"JER_up\":{\n",
    "            'za_qcd_JER_up':[f\"{base_dir}/2016_jesr_za_qcd.root\"],\n",
    "            'za_ewk_JER_up':[f\"{base_dir}/2016_jesr_za_ewk.root\"],\n",
    "            'others_JER_up':[\n",
    "                f\"{base_dir}/2016_jesr_others2.root\",\n",
    "            ]\n",
    "         },     \n",
    "        \"JER_down\":{\n",
    "            'za_qcd_JER_down':[f\"{base_dir}/2016_jesr_za_qcd.root\"],\n",
    "            'za_ewk_JER_down':[f\"{base_dir}/2016_jesr_za_ewk.root\"],\n",
    "            'others_JER_down':[\n",
    "                f\"{base_dir}/2016_jesr_others2.root\",\n",
    "            ]\n",
    "         },     \n",
    "    },\n",
    "    2017:{\n",
    "        \"mc\":{\n",
    "            'za_qcd':[f\"{base_dir}/2017_mc_za_qcd.root\"],\n",
    "            'za_ewk':[f\"{base_dir}/2017_mc_za_ewk.root\"],\n",
    "            'others':[\n",
    "                f\"{base_dir}/2017_mc_others.root\",\n",
    "            ]\n",
    "        },\n",
    "        \"data\":{\n",
    "            'data': [\n",
    "                f\"{base_dir}/2017_data_data.root\",\n",
    "            ]\n",
    "        },\n",
    "        \"fake\":{\n",
    "            'fake': [f\"{base_dir}/2017_fake_fake.root\"],\n",
    "        },\n",
    "        \"fake_up\":{\n",
    "            'fake_up': [f\"{base_dir}/2017_fake_up_fake.root\"],\n",
    "        },\n",
    "        \"fake_down\":{\n",
    "            'fake_down': [f\"{base_dir}/2017_fake_down_fake.root\"],\n",
    "        },\n",
    "        \"JEC_up\":{\n",
    "            'za_qcd_JEC_up':[f\"{base_dir}/2017_jesr_za_qcd.root\"],\n",
    "            'za_ewk_JEC_up':[f\"{base_dir}/2017_jesr_za_ewk.root\"],\n",
    "            'others_JEC_up':[\n",
    "                f\"{base_dir}/2017_jesr_others.root\",\n",
    "            ]\n",
    "         },      \n",
    "        \"JEC_down\":{\n",
    "            'za_qcd_JEC_down':[f\"{base_dir}/2017_jesr_za_qcd.root\"],\n",
    "            'za_ewk_JEC_down':[f\"{base_dir}/2017_jesr_za_ewk.root\"],\n",
    "            'others_JEC_down':[\n",
    "                f\"{base_dir}/2017_jesr_others.root\",\n",
    "            ]\n",
    "         },      \n",
    "        \"JER_up\":{\n",
    "            'za_qcd_JER_up':[f\"{base_dir}/2017_jesr_za_qcd.root\"],\n",
    "            'za_ewk_JER_up':[f\"{base_dir}/2017_jesr_za_ewk.root\"],\n",
    "            'others_JER_up':[\n",
    "                f\"{base_dir}/2017_jesr_others.root\",\n",
    "            ]\n",
    "         },      \n",
    "        \"JER_down\":{\n",
    "            'za_qcd_JER_down':[f\"{base_dir}/2017_jesr_za_qcd.root\"],\n",
    "            'za_ewk_JER_down':[f\"{base_dir}/2017_jesr_za_ewk.root\"],\n",
    "            'others_JER_down':[\n",
    "                f\"{base_dir}/2017_jesr_others.root\",\n",
    "            ]\n",
    "         },      \n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0d429-8015-47b5-bfb3-8edf057aad28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_list = {'DoubleMuon_Run2018A':data_list['DoubleMuon_Run2018A']}\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba014c0-f361-454f-a667-b6a168595102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vals(_vals, _low, _high, clip = True, clip_diff = 0.000001):\n",
    "    \"\"\"Try this\"\"\"\n",
    "\n",
    "    if clip:\n",
    "        _new_vals = np.clip(ak.fill_none(_vals, -999.), _low+clip_diff, _high-clip_diff)\n",
    "    else:\n",
    "        _new_vals = ak.fill_none(_vals, -999.)\n",
    "    return _new_vals\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ead17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c64940c7-59e0-4aa8-9f83-d67f41dea3c3",
   "metadata": {},
   "source": [
    "## Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f2bdd-80cd-4aa8-82cd-ae3779ad3834",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyProcessor(processor.ProcessorABC):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.year = 2016\n",
    "        if \"year\" in kwargs:\n",
    "            self.is_mc = kwargs[\"year\"]\n",
    "        self.is_mc = True\n",
    "        if \"is_mc\" in kwargs:\n",
    "            self.is_mc = kwargs[\"is_mc\"]\n",
    "        self.uncer = \"nom\" # remember to only use: nom, JEC_up, JEC_down, JER_up, JER_down\n",
    "        if \"uncer\" in kwargs:\n",
    "            self.uncer = kwargs[\"uncer\"]\n",
    "        self.is_fake = False\n",
    "        if \"is_fake\" in kwargs:\n",
    "            self.is_fake = kwargs[\"is_fake\"]\n",
    "        self.channel = \"ALL\"\n",
    "        if \"channel\" in kwargs:\n",
    "            self.channel = kwargs[\"channel\"]\n",
    "        # signal region or control region\n",
    "        self.region = \"SR\"\n",
    "        if \"region\" in kwargs:\n",
    "            self.region = kwargs[\"region\"]\n",
    "        # self.fake_unc = \"nom\"\n",
    "        # if \"fake_unc\" in kwargs:\n",
    "        #     self.fake_unc = kwargs[\"fake_unc\"]\n",
    "        print(kwargs)\n",
    "        \n",
    "        if self.region==\"SR\":\n",
    "            self._accumulator = processor.dict_accumulator(\n",
    "                {\n",
    "                    'mjj': coffea_hist.Hist(\n",
    "                        \"Events\",\n",
    "                        coffea_hist.Cat(\"dataset\", \"Dataset\"),\n",
    "                        coffea_hist.Bin('x', r'$m_{jj}$ (GeV)', 8, 500, 2000),\n",
    "                    ),\n",
    "                    'mll': coffea_hist.Hist(\n",
    "                        \"Events\",\n",
    "                        coffea_hist.Cat(\"dataset\", \"Dataset\"),\n",
    "                        coffea_hist.Bin('x', r'$m_{ll}$ (GeV)', 18, 70, 110),\n",
    "                    ),\n",
    "                    'mllv1': coffea_hist.Hist(\n",
    "                        \"Events\",\n",
    "                        coffea_hist.Cat(\"dataset\", \"Dataset\"),\n",
    "                        coffea_hist.Bin('x', r'$m_{ll}$ (GeV)', 12, 70, 110),\n",
    "                    ),\n",
    "                    'mjj_detajj': coffea_hist.Hist(\n",
    "                        \"Events\",\n",
    "                        coffea_hist.Cat(\"dataset\", \"Dataset\"),\n",
    "                        coffea_hist.Bin('x', r'$m_{jj}$ (GeV)', [500, 800, 1200, 2000]),\n",
    "                        coffea_hist.Bin('y', r'$|\\Delta \\eta _{jj}|$ (GeV)', [2.5,4.5,6,10]),\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            self._accumulator = processor.dict_accumulator(\n",
    "                {\n",
    "                    'lowmjj': coffea_hist.Hist(\n",
    "                        \"Events\",\n",
    "                        coffea_hist.Cat(\"dataset\", \"Dataset\"),\n",
    "                        coffea_hist.Bin('x', r'$m_{jj}$ (GeV)', 5, 150, 500),\n",
    "                    ),\n",
    "                    'mll': coffea_hist.Hist(\n",
    "                        \"Events\",\n",
    "                        coffea_hist.Cat(\"dataset\", \"Dataset\"),\n",
    "                        coffea_hist.Bin('x', r'$m_{ll}$ (GeV)', 18, 70, 110),\n",
    "                    ),\n",
    "                    'mllv1': coffea_hist.Hist(\n",
    "                        \"Events\",\n",
    "                        coffea_hist.Cat(\"dataset\", \"Dataset\"),\n",
    "                        coffea_hist.Bin('x', r'$m_{ll}$ (GeV)', 12, 70, 110),\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    def process(self, events):\n",
    "        output = self.accumulator.identity()\n",
    "        dataset = events.metadata['dataset']\n",
    "        lumi = {\n",
    "            2016: 36.33,\n",
    "            2017: 41.53,\n",
    "            2018: 59.74,\n",
    "        }\n",
    "        puid = {\n",
    "            2016: \"puIdMedium\",\n",
    "            2017: \"puIdTight\",\n",
    "            2018: \"puIdTight\",\n",
    "        }\n",
    "        puid_wgt = {\n",
    "            2016: \"M\",\n",
    "            2017: \"T\",\n",
    "            2018: \"T\",\n",
    "        }\n",
    "        # ALL: include MB ME EB EE\n",
    "        # MB: muon barrel\n",
    "        # ME: muon endcap\n",
    "        # EB: electron barrel\n",
    "        # EE: electron endcap\n",
    "        sel_nlep_1 = ((events.HLT_Mu1>0) | (events.HLT_Mu1>0)) & (events.lep==13) & (events.nloosemus < 3) & (events.nlooseeles == 0)\n",
    "        sel_nlep_2 = ((events.HLT_Ele1>0) | (events.HLT_Ele2>0)) & (events.lep==11) & (events.nloosemus == 0) & (events.nlooseeles < 3)\n",
    "        if self.channel==\"ALL\":\n",
    "            sel_nlep = (sel_nlep_1 | sel_nlep_2)\n",
    "        elif self.channel==\"MB\" or self.channel==\"ME\":\n",
    "            sel_nlep = (sel_nlep_1)\n",
    "        else:\n",
    "            sel_nlep = (sel_nlep_2)\n",
    "        events = events.mask[sel_nlep]\n",
    "\n",
    "        # lepton selections\n",
    "        lep_mass = (abs(events.lep) == 11 * 0.00051) + (abs(events.lep) == 13 * 0.10566)\n",
    "        lep1 = ak.zip({\n",
    "            \"pt\": events.ptlep1,\n",
    "            \"eta\": events.etalep1,\n",
    "            \"phi\": events.philep1,\n",
    "            \"mass\": lep_mass,\n",
    "            \"charge\": np.ones(len(events.ptlep1)),\n",
    "            \"pdgId\": events.lep,\n",
    "        }, with_name=\"PtEtaPhiMCandidate\")\n",
    "\n",
    "        lep2 = ak.zip({\n",
    "            \"pt\": events.ptlep2,\n",
    "            \"eta\": events.etalep2,\n",
    "            \"phi\": events.philep2,\n",
    "            \"mass\": lep_mass,\n",
    "            \"charge\": -1 * np.ones(len(events.ptlep2)),\n",
    "            \"pdgId\": events.lep,\n",
    "        }, with_name=\"PtEtaPhiMCandidate\")\n",
    "\n",
    "        sel_lep_1 = (lep1.pt > 25) & (lep2.pt > 25) & (abs(lep1.eta) < 2.5) & (abs(lep2.eta) < 2.5) & (lep1.pdgId == 11) \n",
    "        sel_lep_2 = (lep1.pt > 20) & (lep2.pt > 20) & (abs(lep1.eta) < 2.4) & (abs(lep2.eta) < 2.4) & (lep1.pdgId == 13)\n",
    "        # zpole = lep1 + lep2 ### z boson\n",
    "        sel_lep_4 = (events.massVlep > 70) & (events.massVlep < 110)\n",
    "\n",
    "        events = events.mask[(sel_lep_1 | sel_lep_2) & sel_lep_4]\n",
    "\n",
    "        # photon selections\n",
    "        drla_new = (events.drla!=10)*events.drla\n",
    "        drla2_new = (events.drla2!=10)*events.drla2\n",
    "        # photon selections\n",
    "        pho = ak.zip({\n",
    "            \"pt\": events.photonet,\n",
    "            \"eta\": events.photoneta,\n",
    "            \"phi\": events.photonphi,\n",
    "            \"energy\": events.photone,\n",
    "            \"charge\": np.zeros(len(events.photonet)),\n",
    "            \"pdgId\": 22*np.ones(len(events.photonet)),\n",
    "            \"passEleVeto\": events.passEleVeto,\n",
    "            \"isTrue\": events.isTrue,\n",
    "            \"isprompt\": events.isprompt,\n",
    "            \"drl1a\": drla_new,\n",
    "            \"drl2a\": drla2_new,\n",
    "            \"m_Vgamma\": events.Mva,\n",
    "        }, with_name=\"PtEtaPhiECandidate\")\n",
    "\n",
    "\n",
    "        if self.channel==\"ALL\":\n",
    "            sel_pho_1 = (pho.pt > 20) & (((abs(pho.eta)<2.5) & (abs(pho.eta)>1.566)) | (abs(pho.eta)<1.4442))\n",
    "        elif self.channel==\"MB\" or self.channel==\"EB\":\n",
    "            sel_pho_1 = (pho.pt > 20) & (abs(pho.eta)<1.4442)\n",
    "        else:\n",
    "            sel_pho_1 = (pho.pt > 20) & ((abs(pho.eta)<2.5) & (abs(pho.eta)>1.566))\n",
    "\n",
    "        if self.is_mc:\n",
    "            sel_pho_2 = (pho.drl1a > 0.7) & (pho.drl2a > 0.7) # & (pho.isprompt==1) & (pho.passEleVeto==1)\n",
    "        elif self.is_fake:\n",
    "            sel_pho_2 = (pho.drl1a > 0.7) & (pho.drl2a > 0.7) & (pho.isprompt!=1) # & (pho.passEleVeto==1)\n",
    "        else:\n",
    "            sel_pho_2 = (pho.drl1a > 0.7) & (pho.drl2a > 0.7) # & (pho.passEleVeto)\n",
    "\n",
    "        sel_pho_3 = (pho.m_Vgamma > 100)\n",
    "\n",
    "        events = events.mask[sel_pho_1 & sel_pho_2 & sel_pho_3]\n",
    "\n",
    "        # jet selections\n",
    "        if self.uncer==\"nom\":\n",
    "            postfix=\"\"\n",
    "        else:\n",
    "            postfix=f\"_{self.uncer}\"\n",
    "        jet1 = ak.zip({\n",
    "            \"pt\": events[f\"jet1pt{postfix}\"],\n",
    "            \"eta\": events[f\"jet1eta{postfix}\"],\n",
    "            \"phi\": events[f\"jet1phi{postfix}\"],\n",
    "            \"energy\": events[f\"jet1e{postfix}\"],\n",
    "            \"charge\": np.zeros(len(events[f\"jet1pt{postfix}\"])),\n",
    "            \"dr_a\": events[f\"drj1a{postfix}\"],\n",
    "            \"dr_l1\": events[f\"drj1l{postfix}\"],\n",
    "            \"dr_l2\": events[f\"drj1l2{postfix}\"],\n",
    "            \"puId\": events[f\"jet1{puid[self.year]}{postfix}\"],\n",
    "        }, with_name=\"PtEtaPhiECandidate\")\n",
    "        jet2 = ak.zip({\n",
    "            \"pt\": events[f\"jet2pt{postfix}\"],\n",
    "            \"eta\": events[f\"jet2eta{postfix}\"],\n",
    "            \"phi\": events[f\"jet2phi{postfix}\"],\n",
    "            \"energy\": events[f\"jet2e{postfix}\"],\n",
    "            \"charge\": np.zeros(len(events[f\"jet2pt{postfix}\"])),\n",
    "            \"dr_a\": events[f\"drj2a{postfix}\"],\n",
    "            \"dr_l1\": events[f\"drj2l{postfix}\"],\n",
    "            \"dr_l2\": events[f\"drj2l2{postfix}\"],\n",
    "            \"puId\": events[f\"jet2{puid[self.year]}{postfix}\"],\n",
    "        }, with_name=\"PtEtaPhiECandidate\")\n",
    "\n",
    "        if self.year == 2017:\n",
    "            sel_jet_1 = (((jet1.pt > 30) & (jet1.pt < 50) & (jet1.puId==1) & (abs(jet1.eta)>3.14) | (abs(jet1.eta)<2.65)) | (jet1.pt > 50)) & (abs(jet1.eta) < 4.7) #  \n",
    "            sel_jet_2 = (((jet2.pt > 30) & (jet2.pt < 50) & (jet2.puId==1) & (abs(jet2.eta)>3.14) | (abs(jet2.eta)<2.65)) | (jet2.pt > 50)) & (abs(jet2.eta) < 4.7) #  \n",
    "        else:\n",
    "            sel_jet_1 = (((jet1.pt > 30) & (jet1.pt < 50) & (jet1.puId==1)) | (jet1.pt > 50)) & (abs(jet1.eta) < 4.7) #  & (abs(jet1.eta)<3.14) & (abs(jet1.eta)>2.65)\n",
    "            sel_jet_2 = (((jet2.pt > 30) & (jet2.pt < 50) & (jet2.puId==1)) | (jet2.pt > 50)) & (abs(jet2.eta) < 4.7) #  & (abs(jet2.eta)<3.14) & (abs(jet2.eta)>2.65)\n",
    "        sel_jet_3 = (jet1.dr_a > 0.5) & (jet1.dr_l1 > 0.5) & (jet1.dr_l2 > 0.5) & \\\n",
    "            (jet2.dr_a > 0.5) & (jet2.dr_l1 > 0.5) & (jet2.dr_l2 > 0.5)\n",
    "        if self.region==\"SR\":\n",
    "            sel_jet_4 = (events[f\"Mjj{postfix}\"] > 500) & (abs(jet1.eta-jet2.eta) > 2.5)\n",
    "        else:\n",
    "            sel_jet_4 = (events[f\"Mjj{postfix}\"] > 150) & (events[f\"Mjj{postfix}\"] < 500)\n",
    "        sel_jet_5 = jet1.delta_r(jet2) > 0.5\n",
    "        # sel_jet_3 = (events.Mjj > 150) & (events.Mjj < 400)\n",
    "\n",
    "        events = events.mask[sel_jet_1 & sel_jet_2 & sel_jet_3 & sel_jet_4 & sel_jet_5]\n",
    "\n",
    "        # optimal selections\n",
    "        sel_opt_1 = (events[f\"zepp{postfix}\"] < 2.4)\n",
    "        za = (lep1 + lep2 + pho)\n",
    "        dijet = (jet1 + jet2)\n",
    "        sel_opt_2 = (abs(za.delta_phi(dijet)) > 1.9)\n",
    "\n",
    "        events = events.mask[sel_opt_1 & sel_opt_2]\n",
    "        \n",
    "        # total mask, new objects\n",
    "        tot_mask = (events.event != None)\n",
    "        # weights\n",
    "        tot_mask = ak.fill_none(tot_mask, False) # will remove None events\n",
    "        events = events[tot_mask]\n",
    "        pho = pho[tot_mask]\n",
    "        jet1 = jet1[tot_mask]\n",
    "        jet2 = jet2[tot_mask]\n",
    "        if self.is_mc:\n",
    "            # eletron id sf\n",
    "            eid_scale = (events.lep == 11) * events.ele1_id_scale * events.ele1_reco_scale * events.ele2_id_scale * events.ele2_reco_scale * events.ele_hlt_scale\n",
    "            # muon id sf\n",
    "            mid_scale = (events.lep == 13) * events.muon1_iso_scale * events.muon1_id_scale * events.muon2_id_scale * events.muon2_iso_scale * events.muon_hlt_scale\n",
    "            wgt = events.scalef * events.pileupWeight * events.prefWeight * (eid_scale + mid_scale) * events.photon_id_scale * events.photon_veto_scale * events[f\"puIdweight_{puid_wgt[self.year]}{postfix}\"] * lumi[self.year]\n",
    "            # print(wgt)\n",
    "        elif self.is_fake:\n",
    "            wgt = events.scalef\n",
    "        else:\n",
    "            wgt = np.ones(len(events.run))\n",
    "        # print(ak.to_list(wgt[0:20]))\n",
    "        vals = {}\n",
    "        if self.region==\"SR\":\n",
    "            vals['mjj'] = get_vals(events[f\"Mjj{postfix}\"], 500, 2000)\n",
    "            vals['mll'] = get_vals(events.massVlep, 70, 110)\n",
    "            vals['mllv1'] = get_vals(events.massVlep, 70, 110)\n",
    "            vals['detajj'] = get_vals(abs(jet1.eta-jet2.eta), 2.5, 10)\n",
    "\n",
    "            output[\"mjj\"].fill(dataset = dataset, x = vals['mjj'], weight = wgt)\n",
    "            output[\"mll\"].fill(dataset = dataset, x = vals['mll'], weight = wgt)\n",
    "            output[\"mllv1\"].fill(dataset = dataset, x = vals['mllv1'], weight = wgt)\n",
    "            output[\"mjj_detajj\"].fill(dataset = dataset, x = vals['mjj'], y = vals['detajj'], weight = wgt)\n",
    "        else:\n",
    "            vals['lowmjj'] = get_vals(events[f\"Mjj{postfix}\"], 150, 500)\n",
    "            vals['mll'] = get_vals(events.massVlep, 70, 110)\n",
    "            vals['mllv1'] = get_vals(events.massVlep, 70, 110)\n",
    "\n",
    "            output[\"lowmjj\"].fill(dataset = dataset, x = vals['lowmjj'], weight = wgt)\n",
    "            output[\"mll\"].fill(dataset = dataset, x = vals['mll'], weight = wgt)\n",
    "            output[\"mllv1\"].fill(dataset = dataset, x = vals['mllv1'], weight = wgt)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12c110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee04577-fe61-459d-97a9-4488542c6f53",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbe21e5",
   "metadata": {},
   "source": [
    "## 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84db22ee-fbed-43a5-9b91-b9e70c182e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_hists_2016 = processor.run_uproot_job(files[2016]['mc'],\n",
    "                                'ZPKUCandidates',\n",
    "                                MyProcessor(year=2016,is_mc=True,uncer=\"nom\",is_fake=False,channel=\"EB\",region=\"SR\"),\n",
    "                                processor.futures_executor,\n",
    "                                chunksize=10000,\n",
    "                                executor_args = {'schema': BaseSchema, 'workers': 4}\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ec7ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hists_2016 = processor.run_uproot_job(files[2016]['data'],\n",
    "                                'ZPKUCandidates',\n",
    "                                MyProcessor(year=2016,is_mc=False,uncer=\"nom\",is_fake=False,channel=\"EB\",region=\"SR\"),\n",
    "                                processor.futures_executor,\n",
    "                                chunksize=10000,\n",
    "                                executor_args = {'schema': BaseSchema, 'workers': 4}\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e887a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_hists_2016 = processor.run_uproot_job(files[2016]['fake'],\n",
    "                                'ZPKUCandidates',\n",
    "                                MyProcessor(year=2016,is_mc=False,uncer=\"nom\",is_fake=True,channel=\"EB\",region=\"SR\"),\n",
    "                                processor.futures_executor,\n",
    "                                chunksize=10000,\n",
    "                                executor_args = {'schema': BaseSchema, 'workers': 4}\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c283ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_up_hists_2016 = processor.run_uproot_job(files[2016]['fake_up'],\n",
    "                                'ZPKUCandidates',\n",
    "                                MyProcessor(year=2016,is_mc=False,uncer=\"nom\",is_fake=True,channel=\"EB\",region=\"SR\"),\n",
    "                                processor.futures_executor,\n",
    "                                chunksize=10000,\n",
    "                                executor_args = {'schema': BaseSchema, 'workers': 4}\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e0cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_down_hists_2016 = processor.run_uproot_job(files[2016]['fake_down'],\n",
    "                                'ZPKUCandidates',\n",
    "                                MyProcessor(year=2016,is_mc=False,uncer=\"nom\",is_fake=True,channel=\"EB\",region=\"SR\"),\n",
    "                                processor.futures_executor,\n",
    "                                chunksize=10000,\n",
    "                                executor_args = {'schema': BaseSchema, 'workers': 4}\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfdfa94",
   "metadata": {},
   "source": [
    "### 2016 all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66926f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_cfg = {\n",
    "    \"mc\":{\"is_mc\":True,\"is_fake\":False,\"uncer\":\"nom\"},\n",
    "    \"data\":{\"is_mc\":False,\"is_fake\":False,\"uncer\":\"nom\"},\n",
    "    \"fake\":{\"is_mc\":False,\"is_fake\":True,\"uncer\":\"nom\"},\n",
    "    \"fake_up\":{\"is_mc\":False,\"is_fake\":True,\"uncer\":\"nom\"},\n",
    "    \"fake_down\":{\"is_mc\":False,\"is_fake\":True,\"uncer\":\"nom\"},\n",
    "    \"JEC_up\":{\"is_mc\":True,\"is_fake\":False,\"uncer\":\"JEC_up\"},\n",
    "    \"JEC_down\":{\"is_mc\":True,\"is_fake\":False,\"uncer\":\"JEC_down\"},\n",
    "    \"JER_up\":{\"is_mc\":True,\"is_fake\":False,\"uncer\":\"JER_up\"},\n",
    "    \"JER_down\":{\"is_mc\":True,\"is_fake\":False,\"uncer\":\"JER_down\"},\n",
    "}\n",
    "hist_2016 = {}\n",
    "for iregion in [\"SR\",\"CR\"]:\n",
    "    hist_2016[iregion] = {}\n",
    "    for ichannel in [\"ALL\",\"EB\",\"MB\",\"EE\",\"ME\"]:\n",
    "        hist_2016[iregion][ichannel] = {}\n",
    "        for icate in ['mc','data','fake','fake_up','fake_down','JEC_up','JEC_down','JER_up','JER_down']:\n",
    "            print(\"=========> 2016\",\"channel:\",ichannel,\"icate:\",icate)\n",
    "            hist_2016[iregion][ichannel][icate] = processor.run_uproot_job(files[2016][icate],\n",
    "                                    'ZPKUCandidates',\n",
    "                                    MyProcessor(year=2016,is_mc=cate_cfg[icate][\"is_mc\"],uncer=cate_cfg[icate][\"uncer\"],is_fake=cate_cfg[icate][\"is_fake\"],channel=ichannel,region=iregion),\n",
    "                                    processor.futures_executor,\n",
    "                                    chunksize=10000,\n",
    "                                    executor_args = {'schema': BaseSchema, 'workers': 22}\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07dcd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"plots\"):\n",
    "    os.mkdir(\"plots\")\n",
    "with open(\"plots/plot_2016_tmp.pkl\", \"wb\") as f:\n",
    "    pickle.dump(hist_2016, f)\n",
    "with open(\"plots/plot_2016_tmp.pkl\", \"rb\") as f:\n",
    "    hist_2016 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cd25b6",
   "metadata": {},
   "source": [
    "## 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78623667",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_2017 = {}\n",
    "for iregion in [\"SR\",\"CR\"]:\n",
    "    hist_2017[iregion] = {}\n",
    "    for ichannel in [\"ALL\",\"EB\",\"MB\",\"EE\",\"ME\"]:\n",
    "        hist_2017[iregion][ichannel] = {}\n",
    "        for icate in ['mc','data','fake','fake_up','fake_down','JEC_up','JEC_down','JER_up','JER_down']:\n",
    "            print(\"=========> 2017\",\"channel:\",ichannel,\"icate:\",icate)\n",
    "            hist_2017[iregion][ichannel][icate] = processor.run_uproot_job(files[2017][icate],\n",
    "                                    'ZPKUCandidates',\n",
    "                                    MyProcessor(year=2017,is_mc=cate_cfg[icate][\"is_mc\"],uncer=cate_cfg[icate][\"uncer\"],is_fake=cate_cfg[icate][\"is_fake\"],channel=ichannel,region=iregion),\n",
    "                                    processor.futures_executor,\n",
    "                                    chunksize=10000,\n",
    "                                    executor_args = {'schema': BaseSchema, 'workers': 22}\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9f8abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"plots/plot_2017_tmp.pkl\", \"wb\") as f:\n",
    "    pickle.dump(hist_2017, f)\n",
    "with open(\"plots/plot_2017_tmp.pkl\", \"rb\") as f:\n",
    "    hist_2017 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3391705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = hist.Hist(hist_2017[\"EB\"]['fake_down']['mll'].to_boost())\n",
    "# a[{'dataset':'fake'}].plot()\n",
    "# a[{'dataset':'fake'}].sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbc7114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=hist.Hist(hist_2017[\"SR\"][\"ALL\"][\"JEC_up\"][\"mjj\"].to_boost())\n",
    "# a[{\"dataset\":\"za_ewk\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d802f3e2",
   "metadata": {},
   "source": [
    "## Reorganize plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eb3905",
   "metadata": {},
   "source": [
    "### 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e8f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "restruct_hist_2016 = {}\n",
    "for iregion in hist_2016:\n",
    "    restruct_hist_2016[iregion] = {}\n",
    "    for ichannel in hist_2016[iregion]:\n",
    "        restruct_hist_2016[iregion][ichannel] = {}\n",
    "        # print(\"===>\",ichannel)\n",
    "        for icate in hist_2016[iregion][ichannel]:\n",
    "            # print(\"======>\",icate)\n",
    "            for ivar in hist_2016[iregion][ichannel][icate]:\n",
    "                # print(\"=========>\",ivar)\n",
    "                if ivar in restruct_hist_2016[iregion][ichannel].keys():\n",
    "                    pass\n",
    "                else:\n",
    "                    restruct_hist_2016[iregion][ichannel][ivar] = {}\n",
    "                htmp = hist.Hist(hist_2016[iregion][ichannel][icate][ivar].to_boost())\n",
    "                for isp in htmp.axes['dataset']:\n",
    "                    # print(\"============>\",isp)\n",
    "                    if len(htmp[{'dataset':isp}].axes) == 2:\n",
    "                        h2d_tmp = htmp[{'dataset':isp}]\n",
    "                        # unroll 2D histogram -> 1D histogram\n",
    "                        bin_value = h2d_tmp.values()\n",
    "                        bin_variance = h2d_tmp.variances()\n",
    "\n",
    "                        unroll_htmp = hist.Hist(\n",
    "                            hist.axis.Regular((bin_value).size, 0, (bin_value).size),\n",
    "                            name = \"x\",\n",
    "                            storage = hist.storage.Weight(),\n",
    "                            label = f\"{h2d_tmp.axes.label[0]}:{h2d_tmp.axes.label[1]}\",\n",
    "                        )\n",
    "                        unroll_htmp[...] = np.stack([bin_value.flatten('F'), bin_variance.flatten('F')], axis=-1)\n",
    "                        restruct_hist_2016[iregion][ichannel][ivar][isp] = unroll_htmp\n",
    "                    else:\n",
    "                        restruct_hist_2016[iregion][ichannel][ivar][isp] = htmp[{'dataset':isp}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9e5268",
   "metadata": {},
   "outputs": [],
   "source": [
    "restruct_hist_2016[\"SR\"][\"ALL\"][\"mjj_detajj\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c70cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add total prediction plots\n",
    "for iregion in restruct_hist_2016:\n",
    "    for ichannel in restruct_hist_2016[iregion]:\n",
    "        # print(\"===>\",ichannel)\n",
    "        for ivar in restruct_hist_2016[iregion][ichannel]:\n",
    "            # print(\"======>\",ivar)\n",
    "            htmp=0\n",
    "            htmp_up=0\n",
    "            htmp_down=0\n",
    "            for isp in ['za_qcd','za_ewk','others','fake']:\n",
    "                htmp += restruct_hist_2016[iregion][ichannel][ivar][isp]\n",
    "            for isp in ['za_qcd_JEC_up','za_ewk_JEC_up','others_JEC_up','za_qcd_JER_up','za_ewk_JER_up','others_JER_up','fake_up','fake']:\n",
    "                htmp_up += restruct_hist_2016[iregion][ichannel][ivar][isp]\n",
    "            for isp in ['za_qcd_JEC_down','za_ewk_JEC_down','others_JEC_down','za_qcd_JER_down','za_ewk_JER_down','others_JER_down','fake_down','fake']:\n",
    "                htmp_down += restruct_hist_2016[iregion][ichannel][ivar][isp]\n",
    "            restruct_hist_2016[iregion][ichannel][ivar]['total_pred'] = htmp\n",
    "            restruct_hist_2016[iregion][ichannel][ivar]['total_pred_up'] = htmp_up+htmp*(-1)\n",
    "            restruct_hist_2016[iregion][ichannel][ivar]['total_pred_down'] = htmp_down+htmp*(-1)\n",
    "\n",
    "# store plots\n",
    "\n",
    "with open(\"plots/plot_2016.pkl\", \"wb\") as f:\n",
    "    pickle.dump(restruct_hist_2016, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c177cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=restruct_hist_2016[\"SR\"][\"ALL\"][\"mjj\"][\"others\"]\n",
    "# a.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5113941c",
   "metadata": {},
   "source": [
    "### 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865fca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "restruct_hist_2017 = {}\n",
    "for iregion in hist_2017:\n",
    "    restruct_hist_2017[iregion] = {}\n",
    "    for ichannel in hist_2017[iregion]:\n",
    "        restruct_hist_2017[iregion][ichannel] = {}\n",
    "        # print(\"===>\",ichannel)\n",
    "        for icate in hist_2017[iregion][ichannel]:\n",
    "            # print(\"======>\",icate)\n",
    "            for ivar in hist_2017[iregion][ichannel][icate]:\n",
    "                # print(\"=========>\",ivar)\n",
    "                if ivar in restruct_hist_2017[iregion][ichannel].keys():\n",
    "                    pass\n",
    "                else:\n",
    "                    restruct_hist_2017[iregion][ichannel][ivar] = {}\n",
    "                htmp = hist.Hist(hist_2017[iregion][ichannel][icate][ivar].to_boost())\n",
    "                for isp in htmp.axes['dataset']:\n",
    "                    # print(\"============>\",isp)\n",
    "                    # unroll 2D histogram -> 1D histogram\n",
    "                    if len(htmp[{'dataset':isp}].axes) == 2:\n",
    "                        h2d_tmp = htmp[{'dataset':isp}]\n",
    "                        # unroll 2D histogram -> 1D histogram\n",
    "                        bin_value = h2d_tmp.values()\n",
    "                        bin_variance = h2d_tmp.variances()\n",
    "\n",
    "                        unroll_htmp = hist.Hist(\n",
    "                            hist.axis.Regular((bin_value).size, 0, (bin_value).size),\n",
    "                            name = \"x\",\n",
    "                            storage = hist.storage.Weight(),\n",
    "                            label = f\"{h2d_tmp.axes.label[0]}:{h2d_tmp.axes.label[1]}\",\n",
    "                        )\n",
    "                        unroll_htmp[...] = np.stack([bin_value.flatten('F'), bin_variance.flatten('F')], axis=-1)\n",
    "                        restruct_hist_2017[iregion][ichannel][ivar][isp] = unroll_htmp\n",
    "                    else:\n",
    "                        restruct_hist_2017[iregion][ichannel][ivar][isp] = htmp[{'dataset':isp}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87edf071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add total prediction plots\n",
    "for iregion in restruct_hist_2017:\n",
    "    for ichannel in restruct_hist_2017[iregion]:\n",
    "        # print(\"===>\",ichannel)\n",
    "        for ivar in restruct_hist_2017[iregion][ichannel]:\n",
    "            # print(\"======>\",ivar)\n",
    "            htmp=0\n",
    "            htmp_up=0\n",
    "            htmp_down=0\n",
    "            for isp in ['za_qcd','za_ewk','others','fake']:\n",
    "                htmp += restruct_hist_2017[iregion][ichannel][ivar][isp]\n",
    "            for isp in ['za_qcd_JEC_up','za_ewk_JEC_up','others_JEC_up','za_qcd_JER_up','za_ewk_JER_up','others_JER_up','fake_up','fake']:\n",
    "                htmp_up += restruct_hist_2017[iregion][ichannel][ivar][isp]\n",
    "            for isp in ['za_qcd_JEC_down','za_ewk_JEC_down','others_JEC_down','za_qcd_JER_down','za_ewk_JER_down','others_JER_down','fake_down','fake']:\n",
    "                htmp_down += restruct_hist_2017[iregion][ichannel][ivar][isp]\n",
    "            restruct_hist_2017[iregion][ichannel][ivar]['total_pred'] = htmp\n",
    "            restruct_hist_2017[iregion][ichannel][ivar]['total_pred_up'] = htmp_up+htmp*(-1)\n",
    "            restruct_hist_2017[iregion][ichannel][ivar]['total_pred_down'] = htmp_down+htmp*(-1)\n",
    "\n",
    "\n",
    "# store plots\n",
    "\n",
    "with open(\"plots/plot_2017.pkl\", \"wb\") as f:\n",
    "    pickle.dump(restruct_hist_2017, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd59eeb",
   "metadata": {},
   "source": [
    "### 2016+2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda7c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "restruct_hist_combine = {}\n",
    "# add total prediction plots\n",
    "for iregion in restruct_hist_2016:\n",
    "    restruct_hist_combine[iregion] = {}\n",
    "    for ichannel in restruct_hist_2016[iregion]:\n",
    "        # print(\"===>\",ichannel)\n",
    "        restruct_hist_combine[iregion][ichannel] = {}\n",
    "        for ivar in restruct_hist_2016[iregion][ichannel]:\n",
    "            # print(\"======>\",ivar)\n",
    "            restruct_hist_combine[iregion][ichannel][ivar] = {}\n",
    "            for isp in restruct_hist_2016[iregion][ichannel][ivar]:\n",
    "                restruct_hist_combine[iregion][ichannel][ivar][isp] = restruct_hist_2016[iregion][ichannel][ivar][isp] + restruct_hist_2017[iregion][ichannel][ivar][isp]\n",
    "# store plots\n",
    "\n",
    "with open(\"plots/plot_combine.pkl\", \"wb\") as f:\n",
    "    pickle.dump(restruct_hist_combine, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd987ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restruct_hist_combine['SR']['ALL']['mjj_detajj']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d1bc5d",
   "metadata": {},
   "source": [
    "## Plots for statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4467bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer to: https://github.com/scikit-hep/cabinetry/blob/master/utils/create_histograms.py\n",
    "\n",
    "def get_hists_for_stat(hdict, output_directory, channel, var):\n",
    "    file_name = output_directory + \"/histograms.root\"\n",
    "    with up.recreate(file_name) as f:\n",
    "        for iregion in [\"SR\",\"CR\"]:\n",
    "            if iregion==\"SR\":\n",
    "                f[f\"{iregion}/Data/Nominal\"] = hdict[iregion][channel][var]['data']\n",
    "                f[f\"{iregion}/Signal/Nominal\"] = hdict[iregion][channel][var]['za_ewk']\n",
    "                f[f\"{iregion}/Signal/JEC_up\"] = hdict[iregion][channel][var]['za_ewk_JEC_up']\n",
    "                f[f\"{iregion}/Signal/JEC_down\"] = hdict[iregion][channel][var]['za_ewk_JEC_down']\n",
    "                f[f\"{iregion}/Signal/JER_up\"] = hdict[iregion][channel][var]['za_ewk_JER_up']\n",
    "                f[f\"{iregion}/Signal/JER_down\"] = hdict[iregion][channel][var]['za_ewk_JER_down']\n",
    "                f[f\"{iregion}/ZGammaQCD/Nominal\"] = hdict[iregion][channel][var]['za_qcd']\n",
    "                f[f\"{iregion}/ZGammaQCD/JEC_up\"] = hdict[iregion][channel][var]['za_qcd_JEC_up']\n",
    "                f[f\"{iregion}/ZGammaQCD/JEC_down\"] = hdict[iregion][channel][var]['za_qcd_JEC_down']\n",
    "                f[f\"{iregion}/ZGammaQCD/JER_up\"] = hdict[iregion][channel][var]['za_qcd_JER_up']\n",
    "                f[f\"{iregion}/ZGammaQCD/JER_down\"] = hdict[iregion][channel][var]['za_qcd_JER_down']\n",
    "                f[f\"{iregion}/FakePhoton/Nominal\"] = hdict[iregion][channel][var]['fake']\n",
    "                f[f\"{iregion}/FakePhoton/FakeSyst_up\"] = hdict[iregion][channel][var]['fake_up']\n",
    "                f[f\"{iregion}/FakePhoton/FakeSyst_down\"] = hdict[iregion][channel][var]['fake_down']\n",
    "                f[f\"{iregion}/Others/Nominal\"] = hdict[iregion][channel][var]['others']\n",
    "                f[f\"{iregion}/Others/JEC_up\"] = hdict[iregion][channel][var]['others_JEC_up']\n",
    "                f[f\"{iregion}/Others/JEC_down\"] = hdict[iregion][channel][var]['others_JEC_down']\n",
    "                f[f\"{iregion}/Others/JER_up\"] = hdict[iregion][channel][var]['others_JER_up']\n",
    "                f[f\"{iregion}/Others/JER_down\"] = hdict[iregion][channel][var]['others_JER_down']\n",
    "            else:\n",
    "                # only consider lowmjj distribution in CR\n",
    "                f[f\"{iregion}/Data/Nominal\"] = hdict[iregion][channel][\"lowmjj\"]['data']\n",
    "                f[f\"{iregion}/Signal/Nominal\"] = hdict[iregion][channel][\"lowmjj\"]['za_ewk']\n",
    "                f[f\"{iregion}/Signal/JEC_up\"] = hdict[iregion][channel][\"lowmjj\"]['za_ewk_JEC_up']\n",
    "                f[f\"{iregion}/Signal/JEC_down\"] = hdict[iregion][channel][\"lowmjj\"]['za_ewk_JEC_down']\n",
    "                f[f\"{iregion}/Signal/JER_up\"] = hdict[iregion][channel][\"lowmjj\"]['za_ewk_JER_up']\n",
    "                f[f\"{iregion}/Signal/JER_down\"] = hdict[iregion][channel][\"lowmjj\"]['za_ewk_JER_down']\n",
    "                f[f\"{iregion}/ZGammaQCD/Nominal\"] = hdict[iregion][channel][\"lowmjj\"]['za_qcd']\n",
    "                f[f\"{iregion}/ZGammaQCD/JEC_up\"] = hdict[iregion][channel][\"lowmjj\"]['za_qcd_JEC_up']\n",
    "                f[f\"{iregion}/ZGammaQCD/JEC_down\"] = hdict[iregion][channel][\"lowmjj\"]['za_qcd_JEC_down']\n",
    "                f[f\"{iregion}/ZGammaQCD/JER_up\"] = hdict[iregion][channel][\"lowmjj\"]['za_qcd_JER_up']\n",
    "                f[f\"{iregion}/ZGammaQCD/JER_down\"] = hdict[iregion][channel][\"lowmjj\"]['za_qcd_JER_down']\n",
    "                f[f\"{iregion}/FakePhoton/Nominal\"] = hdict[iregion][channel][\"lowmjj\"]['fake']\n",
    "                f[f\"{iregion}/FakePhoton/FakeSyst_up\"] = hdict[iregion][channel][\"lowmjj\"]['fake_up']\n",
    "                f[f\"{iregion}/FakePhoton/FakeSyst_down\"] = hdict[iregion][channel][\"lowmjj\"]['fake_down']\n",
    "                f[f\"{iregion}/Others/Nominal\"] = hdict[iregion][channel][\"lowmjj\"]['others']\n",
    "                f[f\"{iregion}/Others/JEC_up\"] = hdict[iregion][channel][\"lowmjj\"]['others_JEC_up']\n",
    "                f[f\"{iregion}/Others/JEC_down\"] = hdict[iregion][channel][\"lowmjj\"]['others_JEC_down']\n",
    "                f[f\"{iregion}/Others/JER_up\"] = hdict[iregion][channel][\"lowmjj\"]['others_JER_up']\n",
    "                f[f\"{iregion}/Others/JER_down\"] = hdict[iregion][channel][\"lowmjj\"]['others_JER_down']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0e4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_directory = \"inputs/\"\n",
    "if not os.path.exists(output_directory):\n",
    "    os.mkdir(output_directory)\n",
    "get_hists_for_stat(restruct_hist_combine, output_directory, \"ALL\", \"mjj_detajj\") # You can try another variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0863b7",
   "metadata": {},
   "source": [
    "## Backup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wintercamp]",
   "language": "python",
   "name": "conda-env-wintercamp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
